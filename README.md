# ***AI-ML-Internship-Tasks***

## ***Task 1***
- ***Objective : Exploring and Visualizing a Simple Dataset***
- ***Dataset : Use Iris dataset from seaborn***
- ***Model : No Model is used (Just explore and visualize the dataset)***
### - ***Results :***
- ***It has `150` rows and `5` coluumns***
- ***No Null values***
- ***It has three species , 'setosa','virginica','Virginica'***
- ***The relationship between `sepal length `and `sepal width`, with different colors representing the three `species` of iris flowers.***
- ***`Setosa` (Blue dots): This species tends to have smaller `sepal length` and larger `sepal width` compared to the other two species. They form a distinct cluster at the bottom-left of the plot.***
- ***`Versicolor` (Orange dots): This species generally falls in the middle range for both `sepal length` and `sepal width`, showing some overlap with both Setosa and Virginica.***
- ***`Virginica` (Green dots): This species typically has larger `sepal length` and a wider range of `sepal width`, often clustering towards the upper-right part of the plot.******
- ***The relationship between `petal length` and `petal width`, with different colors again representing the three `species` of iris flowers.***
- ***`Setosa` (Blue dots): This species is very clearly separated from the other two. They exhibit the smallest `petal length` and `petal width`, forming a tight, distinct cluster at the bottom-left of the plot.***
- ***`Versicolor` (Orange dots): This species generally falls in the middle range for both `petal length` and `petal width`. Its cluster is located between Setosa and Virginica, showing some overlap with Virginica but still largely distinct from Setosa.***
- ***`Virginica` (Green dots): This species typically has the largest `petal length` and `petal width`, clustering towards the upper-right part of the plot. There's some overlap with Versicolor, but Virginica generally occupies the region of longer and wider petals.***


## ***Task 2***
- ***Objective : Predict Future Stock Prices (Short-Term)***
- ***Dataset : Stock market data from Yahoo Finance***
- ***Model : LinearRegression()***
### - ***Results :***
  - ***It has `1006` rows and `5` coluumns***
  - ***No Null values***
  - ***After Feature Enginering, we have 1005 rows and 6 columns***
  - ***R2 score is `0.95` which is good, MSE is `4.95` and RMSE is `2.22`***


## ***Task 3***
- ***Objective : Heart Disease Prediction***
- ***Dataset : UCI Heart Disease Data from Kaggle***
- ***Model : LogisticRegression()***
### - ***Results :***
  - ***It has `920` rows and `16` coluumns***
  - ***So many Null values***
  - ***It also have outliers***
  - ***It also has a weired thing in trestbps column that it shows the blood pressureis 0 which is not true***
  - ***We also get an Accuracy Score is `0.53` which is not good***

## ***Task 4***
- ***Objective : House Price Prediction***
- ***Dataset : house-prices-advanced-regression-techniques from Kaggle***
- ***Model : Gradient Boosting***
### - ***Results :***
  - ***It has `1460` rows and `81` coluumns***
  - ***So many Null values***
  - ***Impute missing values using KNN Immputer and Simple Inputer***
  - ***We get a R2 score of `0.91`***





  
